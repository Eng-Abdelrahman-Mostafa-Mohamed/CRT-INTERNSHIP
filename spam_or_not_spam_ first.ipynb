{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "install libraries"
      ],
      "metadata": {
        "id": "XfvhNfn7hEpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install Tokenizer\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "sWGazJW8y8IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import Libraries"
      ],
      "metadata": {
        "id": "fsPw5meIz6Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot  as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "43kJxilIyXnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load emails and labels"
      ],
      "metadata": {
        "id": "3ZkFJLKm0gsd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DcSyb6ouYiR"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('spam.csv',encoding='latin-1')\n",
        "data.isna().sum()\n",
        "data.dropna(axis=1, inplace=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  data spliting into Features and labels"
      ],
      "metadata": {
        "id": "aHqqBvy20noI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=data['v2']\n",
        "y=data['v1']\n",
        "label_encoder = LabelEncoder()\n"
      ],
      "metadata": {
        "id": "ff0mSrMAuadn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "labels frequancy"
      ],
      "metadata": {
        "id": "Kine18ml0xmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(facecolor='silver',figsize=(6,6))\n",
        "plt.hist(y)"
      ],
      "metadata": {
        "id": "64kjLechk7iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = label_encoder.fit_transform(y)\n",
        "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=400)"
      ],
      "metadata": {
        "id": "wZ6tJmCMlkiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token='<OOV>') #may there is words not seen in x_train so model will not put to it sequance umber in testing\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "max_sequence_length = max([len(seq) for seq in X_train_sequences])\n",
        "X_train_padded=pad_sequences(X_train_sequences,maxlen=max_sequence_length)\n",
        "X_test_padded=pad_sequences(X_test_sequences,maxlen=max_sequence_length)\n",
        "#count=0\n",
        "# for i in range (len(X_train_padded[0])):\n",
        "#   if(X_train_padded[0][i]==0):\n",
        "#     count+=1\n",
        "# count"
      ],
      "metadata": {
        "id": "7L7B9VnzEIF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build neural network and Fitting the Model"
      ],
      "metadata": {
        "id": "TB4w4epz02Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=max_sequence_length),#to decrease the dimentinality\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_padded, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 6: Evaluate the Model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test)"
      ],
      "metadata": {
        "id": "EBEU0L2-I2r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "print output of model"
      ],
      "metadata": {
        "id": "V_OEjNXXerIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = np.argmax(model.predict(X_test_padded), axis=1)\n",
        "\n",
        "# Map numeric labels to class names\n",
        "class_names = [\"ham\", \"spam\"]\n",
        "label_output = []\n",
        "\n",
        "# Print predicted labels as \"ham\" or \"spam\" and concatenate with X_test\n",
        "for label in predicted_labels:\n",
        "    label_output.append(class_names[label])\n",
        "    #print(class_names[label])\n",
        "\n",
        "new_data = pd.DataFrame({'Label_from_Model': label_output, 'email': X_test})\n",
        "new_data"
      ],
      "metadata": {
        "id": "n1df7UkmUo8H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}